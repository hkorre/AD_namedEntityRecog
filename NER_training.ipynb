{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Kp0DBqhf2kmp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, spacy, random\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTvEuTlwMhxY"
   },
   "source": [
    "# Load the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY5lUpFoMoCF"
   },
   "source": [
    "## Training data format:\n",
    "A list of tuples, where each tuple contains 1 data point for a text as shown below.\n",
    "\n",
    "The numbers means starting and ending position of the entities in hte text or string. For example 'STREET' starts at position 210 and ends at position 229 of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T15:51:59.461784Z",
     "start_time": "2021-04-24T15:51:59.458969Z"
    },
    "id": "4c_8n5GBTTIM"
   },
   "outputs": [],
   "source": [
    "SAMPLE_TRAIN_DATA = [('BE SUBORDINATED UPON THE REFINANCING OF ANY PRIOR MORTGAGE\\nTHIS DEED OF TRUST...',\n",
    " {'entities': [(210, 229, 'STREET'), (231, 239, 'CITY'), (241, 243, 'STATE'), (244, 249, 'ZIP')]})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRniCAZMP8Bt"
   },
   "source": [
    "### When labeling entities, there're some special cases to be aware of. If you see random characters is linked together with your entities, you need  to include them as part of the entity.\n",
    "\n",
    "Examples:\n",
    "\n",
    "The @ part means entity. @ is not actually in the string, it's just to show you where the entity is at.\n",
    "\n",
    "*   Here is a sample @entity@.\n",
    "*   Here is a sample @!!#entity*@.\n",
    "*   Here is a sample &*( @entity entity@.\n",
    "*   Here is a sample @^Washington D.C.@, blah blah.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RmgiijxN4jN"
   },
   "source": [
    "## Load your training data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PDF = 'data/notes_Redacted.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/29657237/tesseract-ocr-pdf-as-input\n",
    "\n",
    "import pdf2image\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "def pdf_to_img(pdf_file):\n",
    "    return pdf2image.convert_from_path(pdf_file)\n",
    "\n",
    "\n",
    "def ocr_core(file):\n",
    "    text = pytesseract.image_to_string(file)\n",
    "    return text\n",
    "\n",
    "\n",
    "def print_pages(pdf_file):\n",
    "    images = pdf_to_img(pdf_file)\n",
    "    for pg, img in enumerate(images):\n",
    "        print(ocr_core(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 0\n",
      "' \\n\\n \\n\\nADJUSTABLE RATE NOTE\\n(HOME EQUITY CONVERSION)\\nSTATE OF VA\\n\\nAugust 29, 2008\\n\\nPROPERTY ADDRESS FHA Case Number: PF\\nLoan\\n\\nMIN Number:\\nNorfolk, VA 23507\\nNorfolk (City) COUNTY\\n\\n1. DEFINITIONS :\\n\"Borrower\" means each person signing at the end of this Note. \"Lender\" means EverBank Reverse Mortgage LLC and its\\nsuccessors and assigns. \"Secretary\" means the Secretary of Housing and Urban Development or his or her authorized\\nrepresentatives.\\n\\n2. BORROWER\\'S PROMISE TO PAY; INTEREST\\n\\nIn return for amounts to be advanced by Lender up to a maximum principal amount of Four Hundred Seventy Thousand Two\\nHundred Fifty and 00/100 Dollars ($470,250.00), to or for the benefit of Borrower under the terms of a Home Equity\\nConversion Loan Agreement dated August 29, 2008 (\"Loan Agreement\"), Borrower promises to pay to the order of Lender a\\nprincipal amount equal to the sum of all Loan Advances made under the Loan Agreement with interest. All amounts advanced by\\nLender, plus interest, if not paid earlier, are due and payable on July 14, 2087. Interest will be charged on unpaid principal at the\\nrate of Three and 472/1000 percent (3.472%) per year until the full amount of principal has been paid. The interest rate may\\nchange in accordance with Paragraph 5 of this Note. At the end of each month, accrued interest shall be added to and made part of\\nthe principal balance as a Loan Advance and shall likewise thereafter bear interest.\\n\\nThe interest rate required by this Paragraph 2 and Paragraph 5 of this Note is the rate of interest Borrower will pay on the\\noutstanding balance both before and after this Note becomes due and payable as described in Paragraph 7 of this Note, until\\nrepayment in full is made.\\n\\n3. PROMISE TO PAY SECURED\\n\\nBorrower\\'s promise to pay is secured by a mortgage, deed of trust or similar security instrument that is dated the same date as this\\nNote and called the \"Security Instrument.\" The Security Instrument protects the Lender from losses which might result if\\nBorrower defaults under this Note.\\n\\n4, MANNER OF PAYMENT\\n\\n(A) Time\\nBorrower shall pay all outstanding principal and accrued interest to Lender upon receipt of a notice by Lender requiring immediate\\npayment in full, as provided in Paragraph 7 of this Note.\\n\\n(B) Place\\nPayment shall be made at 700 Corporate Blvd., Newburgh, NY 12550 or any such other place as Lender may designate in\\nwriting by notice to Borrower.\\n\\n(C) Limitation of Liability\\n\\nBorrower shall have no personal liability for payment of the debt. Lender shal! enforce the debt only through sale of the Property\\ncovered by the Security Instrument (\"Property\"). If this Note is assigned to the Secretary, the Borrower shall not be liable for any\\ndifference between the mortgage insurance benefits paid to Lender and the outstanding indebtedness, including accrued interest,\\nowed by Borrower at the time of the assignment.\\n\\n5. INTEREST RATE CHANGES\\n\\n(A) Change Date\\nThe interest rate may change on DECEMBER 1, 2008 and on ___ that day of each succeeding year, or _X__ the first day of each\\nsucceeding month. “Change Date” means each date on which the interest rate could change.\\n\\n(B) The Index\\n\\nBeginning with the first Change Date, the interest rate will be based on an Index. “Index\" means the One-Month London\\nInterbank Offered Rate (\"LIBOR\") as made available in the \"Money Rates\" section of the Wall Street Journal.. \"Current Index\"\\nmeans the most recent Index figure available 30 days before the Change Date. If the Index (as defined above) is no longer\\navailable, Lender will use as a new Index any index prescribed by the Secretary. Lender will give Borrower notice of the new\\nIndex,\\n\\n(C) Calculation of Interest Rate Changes\\n\\nBefore cach Change Date, Lender will calculate a new interest rate by adding a margin of 1.000 percentage points to the Current\\nIndex. Subject to the limits stated in Paragraph 5(D) of this Note, this amount will be the new interest rate until the next Change\\nDate\\n\\n \\n\\n \\n\\nFirst Note\\n\\nTAMPA OEE AAAI Th\\n\\n \\n\\n|\\n\\x0c'\n",
      "page 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-12ea250da566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mocr_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# print with newline characters visible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint_pages_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOME_PDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-12ea250da566>\u001b[0m in \u001b[0;36mprint_pages_max\u001b[0;34m(pdf_file, max_page)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'page '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m#print(ocr_core(img))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mocr_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# print with newline characters visible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint_pages_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOME_PDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6301d46c39cc>\u001b[0m in \u001b[0;36mocr_core\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mocr_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     }[output_type]()\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    285\u001b[0m         }\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_filename_base'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1864\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1866\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1867\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def print_pages_max(pdf_file, max_page):\n",
    "    images = pdf_to_img(pdf_file)\n",
    "    for pg, img in enumerate(images):\n",
    "        if pg < max_page:\n",
    "            print('page ' + str(pg))\n",
    "            print(ocr_core(img))\n",
    "            #print(repr(ocr_core(img)))     # print with newline characters visible\n",
    "            \n",
    "print_pages_max(HOME_PDF, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'   apSOsTaBLe RATE SECONDSOTE (HOME EQUITY CONVERSION)  Loan-No. JUNE 13 , 2008  HR 0D EL, ceorcia 31620  1. DEFINITIONS “Borrower” means each person signing at the end of this Note. “Secretary” or “Lender” means the Secretary of Housing and Urban Development or his or her authorized representatives.  [Property Address]     2. BORROWER’S PROMISE TO PAY; INTEREST  In return for amounts to be advanced by Lender up to a maximum principal amount of $ 168,000.00 ; to or for the benefit of Borrower under the terms of a Home Equity Conversion Loan Agreement dated JUNE 13, 2008 (“Loan Agreement”), Borrower promises to pay to the order of Lender a principal amount equa) to the sum of all Loan Advances made under the Loan Agreement with interest. All amounts advanced by Lender, plus interest, if not due earlier, are due and payable on JULY 21 , 2092 . Interest will be charged on unpaid principal at the rate of FOUR AND 140/1000 percent ( 4.1400 %) per year until the full amount of principal has been paid. The interest rate may change in accordance with Paragraph 5 of this Note. Accrued interest shal] be added to the principal balance as a Loan Advance at the end of each month.  3. PROMISE TO PAY SECURED  Borrower’s promise to pay is secured by a mortgage, deed of trust or similar.security instrument that is dated the same date as this Note and called the “Security Instrument” or the “Second Security Instrument.” The Security Instrument protects the Lender from losses which might result if Borrower defaults under this Note. Borrower also executed a First Security Instrument and First Note when the Second Security Instrument and this Note were executed.  4. MANNER OF PAYMENT  (A) Time  Borrower shall pay all outstanding principal and accrued interest to Lender upon receipt of a notice by Lender requiring immediate payment in full, as provided in Paragraph 7 of this Note. (B) Place  Payment shall be made at the Office of the Housing-FHA Comptroller, Director of Mortgage Insurance Accounting and Servicing, 451 7th Street, S.W., Washington, DC 20410, or any such other place as Lender may designate in writing by notice to Borrower, (C) Limitation of Liability  Borrower shall have no personal liability for payment of the debt. Lender shall enforce the debt only through sale of the Property covered by the Security Instrument (\"Property\").  5. INTEREST RATE CHANGES  (A) Change Date  The interest rate may change on the first day of SEPTEMBER, 2008 , and on CJ that day of each succeeding year BS] the first day of each succeeding month. “Change Date” means each date on which the interest rate could change. {B) The Index  Beginning with the first Change Date, the interest rate will be based on an Index. “Index” means the weekly average yield on United States Treasury Securities adjusted to a constant maturity of one-year, as made available by the Federal Reserve Board in Statistical Release H.15 (519). “Current Index” means the most recent Index figure available 30 days before the Change Date. If the Index (as defined above) is no longer available, Lender will use as a new Index any index prescribed by the Secretary. Lender will give Borrower notice of the new Index. (C) Calculation of Interest Rate Changes  Before each Change Date, Lender will calculate a new interest rate by adding a margin of TWO AND 000/1000 percentage points ( 2.00000 %) to the Current Index. Subject to the limits stated in Paragraph 5(D) of this Note, this amount will be the new interest rate until the next Change Date. (D) Limits on Interest Rate Changes  The interest rate will never increase or decrease by more than two percentage points (2.0%) on any single Change Date.  The interest rate will never be more than five percentage points (5.0%) higher or lower than the initial interest rate stated in Paragraph 2 of this Note.  The interest rate will never increase above FOURTEEN AND 140/1000 percent ( 14.14000 %).  (E) Notice of Changes  Lender will give notice to Borrower of any change in the interest rate. The notice must be given at least 25 days before the new interest rate takes effect, and must set forth (i) the date of the notice, (ii) the Change Date, (iii) the old interest rate, (iv) the new interest rate, (v) the Current Index and the date it was published, (vi) the method of calculating the adjusted interest rate, and (vii) any other information which may be required by law from time to time.  First American Loan Production Services Si) HECM ARM Second Note  © 2008 First American Real Estate Solutions LLC \\x0c'\n"
     ]
    }
   ],
   "source": [
    "note_images = pdf_to_img(HOME_PDF)        \n",
    "\n",
    "def get_page_text(images, page):\n",
    "    for pg, img in enumerate(images):\n",
    "        if pg == page:\n",
    "            return ocr_core(img)\n",
    "        \n",
    "print(get_page_text(note_images, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RmgiijxN4jN"
   },
   "source": [
    "### Determine if first or seond note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: First Note...\n",
      "first\n",
      "Example: Second Note...\n",
      "second\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/4666973/how-to-extract-the-substring-between-two-markers\n",
    "\n",
    "import re\n",
    "\n",
    "ANCHOR_NOTE = 'RATE(.+?)NOTE'\n",
    "\n",
    "def find_whichNote(text):\n",
    "    matchObj = re.search(ANCHOR_NOTE, text)\n",
    "    if matchObj is not None:\n",
    "        if len(matchObj.group(1).strip()) < 6:\n",
    "               return 'first'\n",
    "    return 'second'\n",
    "\n",
    "\n",
    "print('Example: First Note...')\n",
    "print(find_whichNote(get_page_text(note_images, 0)))\n",
    "print('Example: Second Note...')\n",
    "print(find_whichNote(get_page_text(note_images, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RmgiijxN4jN"
   },
   "source": [
    "### Find Lender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example1: Type #1...\n",
      "('EverBank Reverse Mortgage LLC', (268, 297))\n",
      "Example2: Type #1...\n",
      "('Mortgage.Shop, LLC', (248, 266))\n",
      "Example3: Type #2...\n",
      "('the Secretary of Housing and Urban Development', (268, 314))\n",
      "('EverBank Reverse Mortgage LLC', (275, 304))\n",
      "(None, None)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/4666973/how-to-extract-the-substring-between-two-markers\n",
    "# https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial\n",
    "\n",
    "import re\n",
    "\n",
    "ANCHOR_LENDER_1 = r'Lender\\s*means\\s*(.+?)\\s*and\\s*its\\s*successors\\s*and\\s*assigns'\n",
    "ANCHOR_LENDER_2 = r'Lender\\s*means\\s*(.+?)\\s*or\\s*his\\s*or\\s*her\\s*authorized\\s*representatives'\n",
    "\n",
    "def convert_text_for_lender(text):\n",
    "    return text.replace('\\n', ' ').replace('\"', '').replace('“','').replace('”','')\n",
    "\n",
    "def find_lender(text):\n",
    "    text = convert_text_for_lender(text)\n",
    "    matchObj_1 = re.search(ANCHOR_LENDER_1, text)\n",
    "    if matchObj_1 is not None:\n",
    "        return matchObj_1.group(1).strip(), matchObj_1.span(1)\n",
    "    else:\n",
    "        matchObj_2 = re.search(ANCHOR_LENDER_2, text)\n",
    "        if matchObj_2 is not None:\n",
    "            return matchObj_2.group(1).strip(), matchObj_2.span(1)\n",
    "    return None, None\n",
    "\n",
    "print('Example1: Type #1...')\n",
    "print(find_lender(get_page_text(note_images, 0)))\n",
    "print('Example2: Type #1...')\n",
    "print(find_lender(get_page_text(note_images, 1)))\n",
    "print('Example3: Type #2...')\n",
    "print(find_lender(get_page_text(note_images, 2)))\n",
    "print(find_lender(get_page_text(note_images, 15)))\n",
    "print(find_lender(get_page_text(note_images, 18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RmgiijxN4jN"
   },
   "source": [
    "### Find Maximum Principal Amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$168,000.00\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/46163913/extract-currency-amount-from-string-in-python\n",
    "\n",
    "import re\n",
    "\n",
    "ANCHOR_MAXIMUM_PRINCIPAL_AMOUNT = 'maximum principal amount of'\n",
    "MAX_PRINCIPAL_LENGTH = 100\n",
    "\n",
    "def find_maximumPrincipalAmount(text):\n",
    "    idx_MPA = text.find(ANCHOR_MAXIMUM_PRINCIPAL_AMOUNT)\n",
    "    start_idx = idx_MPA + len(ANCHOR_MAXIMUM_PRINCIPAL_AMOUNT)\n",
    "    principal_list = re.findall(\"(?:[\\£\\$\\€]{1}[\\s]*[,\\d]+\\.?\\d*)\",text[start_idx:start_idx+MAX_PRINCIPAL_LENGTH])\n",
    "    if principal_list is not None and len(principal_list) != 0:\n",
    "        return principal_list[0].replace(\" \", \"\")\n",
    "    return None\n",
    "\n",
    "#print(find_maximumPrincipalAmount(get_page_text(note_images, 0)))\n",
    "print(find_maximumPrincipalAmount(get_page_text(note_images, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RmgiijxN4jN"
   },
   "source": [
    "### Find Maturity Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087-07-14\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/19994396/best-way-to-identify-and-extract-dates-from-text-python\n",
    "\n",
    "import datefinder\n",
    "\n",
    "ANCHOR_MATURITY_DATE = 'are due and payable on'\n",
    "MAX_DATE_LENGTH = 20\n",
    "\n",
    "def find_maturityDate(text):\n",
    "    idx_MD = text.find(ANCHOR_MATURITY_DATE)\n",
    "    start_idx = idx_MD + len(ANCHOR_MATURITY_DATE)\n",
    "    matches = datefinder.find_dates(text[start_idx:start_idx+MAX_DATE_LENGTH])\n",
    "    for match in matches:\n",
    "        return match.date()\n",
    "    \n",
    "dateFromDoc = find_maturityDate(get_page_text(note_images, 0))\n",
    "print(dateFromDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RmgiijxN4jN"
   },
   "source": [
    "### Create csv, bookmark list, and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1...\n",
      "page 2...\n",
      "page 3...\n",
      "page 4...\n",
      "page 5...\n",
      "page 6...\n",
      "page 7...\n",
      "page 8...\n",
      "page 9...\n",
      "page 10...\n",
      "page 11...\n",
      "page 12...\n",
      "page 13...\n",
      "page 14...\n",
      "page 15...\n",
      "page 16...\n",
      "page 17...\n",
      "page 18...\n",
      "page 19...\n",
      "page 20...\n",
      "page 21...\n",
      "page 22...\n",
      "page 23...\n",
      "page 24...\n",
      "page 25...\n",
      "page 26...\n",
      "page 27...\n",
      "page 28...\n",
      "page 29...\n",
      "page 30...\n",
      "page 31...\n",
      "page 32...\n",
      "page 33...\n",
      "page 34...\n",
      "page 35...\n",
      "page 36...\n",
      "page 37...\n",
      "page 38...\n",
      "page 39...\n",
      "page 40...\n",
      "page 41...\n",
      "page 42...\n",
      "page 43...\n",
      "page 44...\n",
      "page 45...\n",
      "page 46...\n",
      "page 47...\n",
      "page 48...\n",
      "page 49...\n",
      "page 50...\n",
      "page 51...\n",
      "page 52...\n",
      "page 53...\n",
      "page 54...\n",
      "page 55...\n",
      "page 56...\n",
      "page 57...\n",
      "page 58...\n",
      "page 59...\n",
      "page 60...\n",
      "page 61...\n",
      "page 62...\n",
      "page 63...\n",
      "page 64...\n",
      "page 65...\n",
      "page 66...\n",
      "page 67...\n",
      "page 68...\n",
      "page 69...\n",
      "page 70...\n",
      "page 71...\n",
      "page 72...\n",
      "page 73...\n",
      "page 74...\n",
      "page 75...\n",
      "page 76...\n",
      "page 77...\n",
      "page 78...\n",
      "page 79...\n",
      "page 80...\n",
      "page 81...\n",
      "page 82...\n",
      "page 83...\n",
      "page 84...\n",
      "page 85...\n",
      "page 86...\n",
      "page 87...\n",
      "page 88...\n",
      "page 89...\n",
      "page 90...\n",
      "page 91...\n",
      "page 92...\n",
      "page 93...\n",
      "page 94...\n",
      "page 95...\n",
      "page 96...\n",
      "page 97...\n",
      "page 98...\n",
      "page 99...\n",
      "page 100...\n",
      "page 101...\n",
      "page 102...\n",
      "page 103...\n",
      "page 104...\n",
      "page 105...\n",
      "page 106...\n",
      "page 107...\n",
      "page 108...\n",
      "page 109...\n",
      "page 110...\n",
      "page 111...\n",
      "page 112...\n",
      "page 113...\n",
      "page 114...\n",
      "page 115...\n",
      "page 116...\n",
      "page 117...\n",
      "page 118...\n",
      "page 119...\n",
      "page 120...\n",
      "page 121...\n",
      "page 122...\n",
      "page 123...\n",
      "page 124...\n",
      "page 125...\n",
      "page 126...\n",
      "page 127...\n",
      "page 128...\n",
      "page 129...\n",
      "page 130...\n",
      "page 131...\n",
      "page 132...\n",
      "page 133...\n",
      "page 134...\n",
      "page 135...\n",
      "page 136...\n",
      "page 137...\n",
      "page 138...\n",
      "page 139...\n",
      "page 140...\n",
      "page 141...\n",
      "page 142...\n",
      "page 143...\n",
      "page 144...\n",
      "page 145...\n",
      "page 146...\n",
      "page 147...\n",
      "page 148...\n",
      "page 149...\n",
      "Data rangling Done.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "CSV_FILENAME = \"mortgage_notes.csv\"\n",
    "CSV_FIELDS = ['page', 'note type', 'lender', 'max principal', 'maturity date']\n",
    "\n",
    "def process_images(images, max_page):\n",
    "    bookmark_list = []\n",
    "    training_data = []\n",
    "    \n",
    "    with open(CSV_FILENAME, 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(CSV_FIELDS)\n",
    "        \n",
    "        for pg, img in enumerate(images):\n",
    "            print('page ' + str(pg+1) + '...')\n",
    "            line = []\n",
    "            training_entry = ()\n",
    "            text = ocr_core(img)\n",
    "            \n",
    "            line.append(pg+1)\n",
    "            \n",
    "            bookmark_type = find_whichNote(text)\n",
    "            line.append(bookmark_type)\n",
    "            bookmark_list.append(bookmark_type)\n",
    "            \n",
    "            lender_name, lender_span = find_lender(text)\n",
    "            line.append(lender_name)\n",
    "            line.append(find_maximumPrincipalAmount(text))\n",
    "            line.append(find_maturityDate(text))\n",
    "            \n",
    "            if lender_name is not None:\n",
    "                training_data.append((convert_text_for_lender(text), {'entities': [(lender_span[0], lender_span[1], 'LENDER')]}))\n",
    "            \n",
    "            \n",
    "            csvwriter.writerow(line)\n",
    "            \n",
    "            if max_page != 0:\n",
    "                if pg+1 >= max_page:\n",
    "                    break\n",
    "    \n",
    "    return bookmark_list, training_data\n",
    "\n",
    "\n",
    "#test\n",
    "bookmarks, TRAIN_DATA = process_images(note_images, 149)\n",
    "\n",
    "\n",
    "print('Data rangling Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piAaUgMU4jU2"
   },
   "source": [
    "# Adding bookmarks to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0...first\n",
      "Page 1...first\n",
      "Page 2...second\n",
      "Page 3...second\n",
      "Page 4...second\n",
      "Page 5...first\n",
      "Page 6...second\n",
      "Page 7...first\n",
      "Page 8...first\n",
      "Page 9...second\n",
      "Page 10...first\n",
      "Page 11...first\n",
      "Page 12...first\n",
      "Page 13...second\n",
      "Page 14...second\n",
      "Page 15...first\n",
      "Page 16...second\n",
      "Page 17...second\n",
      "Page 18...first\n",
      "Page 19...second\n",
      "Page 20...first\n",
      "Page 21...first\n",
      "Page 22...second\n",
      "Page 23...first\n",
      "Page 24...second\n",
      "Page 25...second\n",
      "Page 26...second\n",
      "Page 27...first\n",
      "Page 28...first\n",
      "Page 29...first\n",
      "Page 30...first\n",
      "Page 31...first\n",
      "Page 32...first\n",
      "Page 33...second\n",
      "Page 34...second\n",
      "Page 35...second\n",
      "Page 36...second\n",
      "Page 37...first\n",
      "Page 38...second\n",
      "Page 39...second\n",
      "Page 40...first\n",
      "Page 41...second\n",
      "Page 42...first\n",
      "Page 43...first\n",
      "Page 44...second\n",
      "Page 45...second\n",
      "Page 46...second\n",
      "Page 47...second\n",
      "Page 48...first\n",
      "Page 49...second\n",
      "Page 50...first\n",
      "Page 51...second\n",
      "Page 52...second\n",
      "Page 53...second\n",
      "Page 54...first\n",
      "Page 55...first\n",
      "Page 56...first\n",
      "Page 57...first\n",
      "Page 58...second\n",
      "Page 59...first\n",
      "Page 60...first\n",
      "Page 61...second\n",
      "Page 62...second\n",
      "Page 63...first\n",
      "Page 64...first\n",
      "Page 65...first\n",
      "Page 66...first\n",
      "Page 67...first\n",
      "Page 68...first\n",
      "Page 69...first\n",
      "Page 70...first\n",
      "Page 71...first\n",
      "Page 72...second\n",
      "Page 73...second\n",
      "Page 74...second\n",
      "Page 75...second\n",
      "Page 76...first\n",
      "Page 77...first\n",
      "Page 78...first\n",
      "Page 79...second\n",
      "Page 80...second\n",
      "Page 81...second\n",
      "Page 82...second\n",
      "Page 83...second\n",
      "Page 84...first\n",
      "Page 85...second\n",
      "Page 86...first\n",
      "Page 87...first\n",
      "Page 88...first\n",
      "Page 89...first\n",
      "Page 90...second\n",
      "Page 91...first\n",
      "Page 92...second\n",
      "Page 93...first\n",
      "Page 94...second\n",
      "Page 95...second\n",
      "Page 96...first\n",
      "Page 97...first\n",
      "Page 98...first\n",
      "Page 99...second\n",
      "Page 100...second\n",
      "Page 101...first\n",
      "Page 102...first\n",
      "Page 103...first\n",
      "Page 104...first\n",
      "Page 105...first\n",
      "Page 106...second\n",
      "Page 107...first\n",
      "Page 108...first\n",
      "Page 109...first\n",
      "Page 110...second\n",
      "Page 111...second\n",
      "Page 112...second\n",
      "Page 113...first\n",
      "Page 114...second\n",
      "Page 115...second\n",
      "Page 116...second\n",
      "Page 117...second\n",
      "Page 118...second\n",
      "Page 119...first\n",
      "Page 120...second\n",
      "Page 121...second\n",
      "Page 122...second\n",
      "Page 123...second\n",
      "Page 124...second\n",
      "Page 125...second\n",
      "Page 126...second\n",
      "Page 127...first\n",
      "Page 128...second\n",
      "Page 129...first\n",
      "Page 130...first\n",
      "Page 131...first\n",
      "Page 132...first\n",
      "Page 133...first\n",
      "Page 134...first\n",
      "Page 135...first\n",
      "Page 136...second\n",
      "Page 137...second\n",
      "Page 138...first\n",
      "Page 139...second\n",
      "Page 140...second\n",
      "Page 141...first\n",
      "Page 142...first\n",
      "Page 143...second\n",
      "Page 144...second\n",
      "Page 145...first\n",
      "Page 146...second\n",
      "Page 147...first\n",
      "Page 148...second\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/42546066/add-a-bookmark-to-a-pdf-with-pypdf2?noredirect=1&lq=1\n",
    "\n",
    "NEW_PDF = 'data/notes_Bookmarked.pdf'\n",
    "\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "\n",
    "def pdf_add_bookmarks(bookmark_list):\n",
    "    output = PdfFileWriter()\n",
    "    input = PdfFileReader(open(HOME_PDF, 'rb'))\n",
    "        \n",
    "    for cnt, bookmark in enumerate(bookmark_list):\n",
    "        print('Page ' + str(cnt) + '...' + bookmark)\n",
    "        output.addPage(input.getPage(cnt))\n",
    "        output.addBookmark(bookmark, cnt, parent=None) # add bookmark\n",
    "        \n",
    "    output.setPageMode(\"/UseOutlines\") #This is what tells the PDF to open to bookmarks\n",
    "    \n",
    "    #save the new file\n",
    "    outputStream = open(NEW_PDF,'wb')\n",
    "    output.write(outputStream)\n",
    "    outputStream.close()\n",
    "    \n",
    "pdf_add_bookmarks(bookmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'/Title': 'first', '/Page': IndirectObject(3, 0), '/Type': '/Fit'}, {'/Title': 'first', '/Page': IndirectObject(7, 0), '/Type': '/Fit'}, {'/Title': 'second', '/Page': IndirectObject(10, 0), '/Type': '/Fit'}, {'/Title': 'second', '/Page': IndirectObject(13, 0), '/Type': '/Fit'}, {'/Title': 'second', '/Page': IndirectObject(16, 0), '/Type': '/Fit'}, {'/Title': 'first', '/Page': IndirectObject(19, 0), '/Type': '/Fit'}]\n"
     ]
    }
   ],
   "source": [
    "#https://pspdfkit.com/blog/2019/understanding-pdf-outline/\n",
    "# Note: Bookmarks show up in table of contents in Apple Preview app\n",
    "\n",
    "def pdf_get_bookmarks():\n",
    "    input = PdfFileReader(open(NEW_PDF, 'rb'))\n",
    "    print(input.getOutlines())\n",
    "    \n",
    "pdf_get_bookmarks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piAaUgMU4jU2"
   },
   "source": [
    "# Create new model. (Just run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:53:56.667069Z",
     "start_time": "2021-05-11T16:53:55.898004Z"
    },
    "id": "nQ7gE01F2aRg"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f2c004a9ca0>)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHH3D0Fp5Inw"
   },
   "source": [
    "# Register the entity label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "bUw_OoDj5Hck"
   },
   "outputs": [],
   "source": [
    "for lb in ['LENDER']: # Change the label.\n",
    "    ner.add_label(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEgogOqP5blh"
   },
   "source": [
    "# Train the NER model (Just run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/56642816/valueerror-e024-could-not-find-an-optimal-move-to-supervise-the-parser\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "        \n",
    "    return cleaned_data\n",
    "    \n",
    "TRAIN_DATA_CLEANED = trim_entity_spans(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:27:12.020904Z",
     "start_time": "2021-05-11T17:22:14.476260Z"
    },
    "code_folding": [],
    "id": "euK4yOoSuBN1",
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th. [language.py:635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 2836.633828568485}\n",
      "Losses {'ner': 425.1994468195207}\n",
      "Losses {'ner': 243.05948116840983}\n",
      "Losses {'ner': 104.35214403859176}\n",
      "Losses {'ner': 388.8365342151518}\n",
      "Losses {'ner': 211.5396421293567}\n",
      "Losses {'ner': 296.46296783464794}\n",
      "Losses {'ner': 142.7610870286553}\n",
      "Losses {'ner': 59.962939752413895}\n",
      "Losses {'ner': 120.95574612311958}\n",
      "Losses {'ner': 378.8246700602713}\n",
      "Losses {'ner': 37.99119814317774}\n",
      "Losses {'ner': 98.99729767126925}\n",
      "Losses {'ner': 119.24399894472346}\n",
      "Losses {'ner': 319.1566313014298}\n",
      "Losses {'ner': 84.60641878458628}\n",
      "Losses {'ner': 213.95878366663536}\n",
      "Losses {'ner': 120.10477835477637}\n",
      "Losses {'ner': 94.5823526872113}\n",
      "Losses {'ner': 66.96850433390249}\n",
      "Losses {'ner': 208.66254326796755}\n",
      "Losses {'ner': 66.3493080217737}\n",
      "Losses {'ner': 88.43556549306017}\n",
      "Losses {'ner': 61.381690821964234}\n",
      "Losses {'ner': 31.291161883620873}\n",
      "Losses {'ner': 98.29964230522457}\n",
      "Losses {'ner': 87.43065921663813}\n",
      "Losses {'ner': 219.68863658764323}\n",
      "Losses {'ner': 201.30958014249367}\n",
      "Losses {'ner': 158.55906010150534}\n",
      "Losses {'ner': 101.11906302525595}\n",
      "Losses {'ner': 239.68247555658573}\n",
      "Losses {'ner': 132.59736977753005}\n",
      "Losses {'ner': 181.30994991534098}\n",
      "Losses {'ner': 235.14120386271884}\n",
      "Losses {'ner': 139.4961242193474}\n",
      "Losses {'ner': 110.51721322265789}\n",
      "Losses {'ner': 225.92820284879426}\n",
      "Losses {'ner': 89.76553033317195}\n",
      "Losses {'ner': 366.31017895340113}\n",
      "Losses {'ner': 138.4066638119178}\n",
      "Losses {'ner': 170.48165306262442}\n",
      "Losses {'ner': 133.12073862143652}\n",
      "Losses {'ner': 133.00625984362082}\n",
      "Losses {'ner': 88.08542071258992}\n",
      "Losses {'ner': 65.73820268675124}\n",
      "Losses {'ner': 92.92889001715587}\n",
      "Losses {'ner': 134.29128641380197}\n",
      "Losses {'ner': 139.50082561791064}\n",
      "Losses {'ner': 146.58855169742532}\n",
      "Training DONE.\n"
     ]
    }
   ],
   "source": [
    "optimizer = nlp.begin_training()\n",
    "\n",
    "move_names = list(ner.move_names) # Only for new model\n",
    "\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    for itn in range(50):\n",
    "        random.shuffle(TRAIN_DATA_CLEANED)\n",
    "        batches = minibatch(TRAIN_DATA_CLEANED, size = sizes)\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd = optimizer, drop = 0.35, losses = losses)\n",
    "        print(\"Losses\", losses)\n",
    "        \n",
    "print('Training DONE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Zn3vMUq6rBc"
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T17:29:40.244434Z",
     "start_time": "2021-05-11T17:29:40.197062Z"
    },
    "id": "TIwkNi2C2aRh"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_models/lenders_model'\n",
    "nlp.to_disk(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IszBztOy7XKx"
   },
   "source": [
    "# How to use the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQmVerUrNU1P"
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "xO_-bdKGNR5g"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XRJVJueNX0M"
   },
   "source": [
    "## Extract the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T19:43:39.724599Z",
     "start_time": "2021-05-10T19:43:39.707190Z"
    },
    "id": "mChGX2Y_2aRj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENDER EverBank Reverse Mortgage LLC\n",
      "Extract DONE.\n"
     ]
    }
   ],
   "source": [
    "TEST_SENTENCE = convert_text_for_lender(get_page_text(note_images, 0))\n",
    "\n",
    "doc = nlp(TEST_SENTENCE)\n",
    "for entity in doc.ents:\n",
    "    print(entity.label_, entity.text)\n",
    "\n",
    "print(\"Extract DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "colab": {
   "collapsed_sections": [],
   "name": "NER training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "195.667px",
    "left": "911px",
    "right": "20px",
    "top": "120px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
